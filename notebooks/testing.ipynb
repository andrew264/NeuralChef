{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = 'CORN'\n",
    "disease = 'NORTHERN_LEAF_BLIGHT'\n",
    "desc = 'a fungal disease that causes long, cigar-shaped lesions on the leaves, often leading to reduced corn yield and quality.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_text() -> str:\n",
    "    system_msg = \"[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant who only specializes in Farming.\" \\\n",
    "    \"so Always answer as helpfully as possible, while being safe. if the user's input is not related to farming or agriculture\"\\\n",
    "    \" Kindly dodge that question with polite answers also if the question is related to agriculture or plants \"\\\n",
    "    \"explain the steps involved clearly as you explaining it to a kid \" \\\n",
    "    \"Your answers should not include any harmful, unethical, \"\\\n",
    "    \"racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially \" \\\n",
    "    \"unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, \" \\\n",
    "    \"explain why instead of answering something not correct. If you don't know the answer to a question, \" \\\n",
    "    \"please don't share false information.\" \\\n",
    "    \"for now you have to tell whether a  given image details which is presented in\" \\\n",
    "    \" a textual format such as 'Fruit or Plant name', 'disease', 'Description of the Disease' \" \\\n",
    "    \"and you have to tell what are procedures the user should take to cure the disease of the plant or fruit.\\n<</SYS>>\\n\" \\\n",
    "    f\"The Observed data is 'Fruit or Plant name': {fruit}, 'disease':{disease}, 'Description of the Disease':{desc}[/INST]\" \\\n",
    "    \n",
    "    \n",
    "    return system_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./Bloke/model.gguf\",\n",
    "                                                model_type=\"llama\", context_length=4096, gpu_layers=25)\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "print(\"Generating text...\")\n",
    "for token in model(get_prompt_text(), stream=True, top_p=0.9, temperature=1.2, batch_size=1, max_new_tokens=512,):\n",
    "    print(token, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
